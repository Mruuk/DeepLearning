para fazer validação em um algoritmo, são necessárias duas bases de dados diferentes,
base de treinamento e base teste.

se gera um modelo do seu algoritmo por meu da base de dados de treinamento, exemplo usando o navbias,
ele vai ler esses dados e gerar uma tabela d probabilidade, logo após terá uma outra
base da dados de teste, onde essa base da dados será submetida para essa tabela de probabilidade
e o navbais fará as previsões e as classificações.

nesse primeiro momento foi trabalhando com divisão da base de dados entre treinamento e teste.

dicas:  para base de dados grande, pode utilizar 90% da base de dados para treinar
        e os outros 10% para testar.
        para base de dados menoras, coloca por volta de 70-80% parar treinar e o que sobrar para testar

o problema é que às vezes se tem registros que estao na base de dados de teste
seriam otimos previsores, e seria muito melhor tê-los na base de treinamento ao invés da de teste
exemplo, um registro que oferece uma boa generalização das caracteriscas de uma pessoa.
iria contribuir muito mais se esses regirtros estivesse na base de treinamento


AI que entra essa abordagem, o K-fold cross validation, validação cruzada.
o k é um valor definido.
vai-se quebrar a a base de dados a quantidade que o valor K determinar

o metodo de validação mais utilizado é a validação cruzada, por ser mais eficiente.
não se ver validações de um algoritmo onde se divide a base de dados para teste e treinamento.
valor 10 pra validação cruzada é de costume, não faz muito sentido usar um valor muito alto,
e por padrão o valor 10 se tornou muito aceito na comunidade científica.
ela é bastante indicada para base de dados menores.