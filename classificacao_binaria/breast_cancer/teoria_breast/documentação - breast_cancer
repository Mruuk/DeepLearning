#pandas utilizado para leitura da base da dados csv
import pandas as pd

#instanciando a base de dados de entrada
previsores = pd.read_csv('breast_cancer/recursos/entradas_breast.csv')

#instanciando a base de dados de saida
classe = pd.read_csv('breast_cancer/recursos/saidas_breast.csv')

#importando os modelos de treinamento
from sklearn.model_selection import train_test_split
previsores_treinamento, previsores_teste, classe_treinamente, classe_teste = train_test_split(previsores, classe, test_size=0.25)

#importando o framework keras
import keras

#importando o modelo sequencial, que agrupa uma pilha linear de camadas
from keras.models import Sequential

#importando camada do tipo dense, uma camada densa cujo cada neuronio da camada
#de entrada interage com cada neuronio das camadas subsequentes, 
#tbm chamada de rede neural fully connected
from keras.layers import Dense

#criando uma nova rede neural
classificador = Sequential()

#instanciando rede densa; units: numero de neuronios da camada oculta, total de atributos previsores
#que vale ao numero de previsores, a formula é, somar as entradas mais as saidas e dividir por 2,
#neste caso, (30 + 1)/2 = 15,5 => 16
#activation =>  função de ativação para a camada, neste caso relu
#kernel_initializer => como fazer a inicialização ddos pesos, por padrão => random_uniform
#input_dim= quantos elementos existem na camada de entrada, neste caso 30
#a criação da camada de entrada é feita junto da primeira camada oculta
classificador.add(Dense(units = 16, activation= 'relu', 
                        kernel_initializer= 'random_uniform', input_dim = 30))
#criando a camada de saida
#como a resposta é maligno ou benigno, 0 ou 1, neste caso apenas um saida
#activation => sigmoid por ser binaria, 0 ou 1
classificador.add(Dense(units= 1, activation='sigmoid'))

#compilar a rede neural
#optimizer => função dos ajustes de peso, descida do gradiente ou descida do gradiente stochastic
#adam => função de descida do gradiente stochastic
#loss => função de perda tem o mean squared error(usados para problemas de regressao)
#binary_crossentropy => usada qndo trabalha com problemas de classificação binária
#metrics => a a metrica parar fazer a avaliação
#binary_accuracy =>  quantos registros foram classificados corretamente e
#quando foram errados, e binary por ser uma classificação de duas classes
classificador.compile(optimizer= 'adam', loss = 'binary_crossentropy',
                  metrics = ['binary_accuracy'])

#treinamento
#fit, encaixar, passando como paramentrs a base de dados, previsores e classe
#batch_size => vai calcular o erro para 10 registros e dps atualizar os pesos
#dps calcula pra mais 10 e faz o ajuste dos previsores
#como a descida do gradiente stochastico de 10 em 10
#epochs => as epocas, são quantas vezes fará os ajustes dos pesos
classificador.fit(previsores_treinamento, classe_treinamento,
                  batch_size = 10, epochs = 100)

#previsoes recebe o classificador rodando o previsores_teste
# passa cada um dos registros para rede neural,
# que por sua vez executa cada um dos calculo pré definidos, e retorna um valor de probabilidade
previsoes = classificador.predict(previsores_teste)

#converte para true ou false, métrica de 0.5, maior que 0.5 = true
previsoes = (previsoes > 0.5)

#importando sklearn um verificador comparativo
from sklearn.metrics import confusion_matrix, accuracy_score
#recursos manual de verificação

#compara os parametros
precisao = accuracy_score(classe_teste, previsoes)

#compara e exibe em matrix
# matriz 0,0 = benigno acerto; 0,1 = benigno erro; 1,0 = maligno erro; 1,1 = maligno acerto
matriz = confusion_matrix(classe_teste, previsoes)


#mesma comparação do sklearn mas utilizado o próprio keras
#vai pegar os previsores_teste, vai submeter para rede neural,
# ela por sua vez vai fazer a respectiva previsão,
# e ja vai fazer a avaliação
# 0 => função de erro; 1 => função de acerto
resultado = classificador.evaluate(previsores_teste, classe_teste)


============================================================================


import keras
from keras.models import Sequential
from keras.layers import Dense
classificador = Sequential()

#add de mais uma camada, note que só na criação da primeira camada oculta que necessita
#setar a camada de entrada
classificador.add(Dense(units = 16, activation= 'relu', 
                        kernel_initializer= 'random_uniform', input_dim = 30))
classificador.add(Dense(units = 16, activation= 'relu', 
                        kernel_initializer= 'random_uniform'))
classificador.add(Dense(units= 1, activation='sigmoid'))

#import tensorflow para a utilização do optimizers.Adam
#obs sem o framework tensorflow, o keras não encontrava o module optimizers e a class Adam
import tensorflow as tf
#deixamos de usar o otimizador default e melhoramos os parametros
#learning_rate => o parametro serve para chegar no minimo global, qnto menor o paramentro,
    #ponto a ponto vai descendo o gradiente em busca do minimo global
#decay => auxilia o learning_rate, ele vai indicar quanto que o ele vai ser decrementado
    #a cada atualização de pesos, vai baixando gradativamente o learning_rate,
    #acelerando assim o processo
#clipvalue => prende o valor, max e min, para evitar que saia muito do padrão,
    #mantendo sempre a descida do gradiente, ate chegar no minimo global
otimizador = tf.keras.optimizers.Adam(learning_rate = 0.001, decay = 0.0001, clipvalue = 0.5)
classificador.compile(optimizer= otimizador, loss = 'binary_crossentropy',
                      metrics = ['binary_accuracy'])

#classificador.compile(optimizer= 'adam', loss = 'binary_crossentropy',
#                      metrics = ['binary_accuracy'])
classificador.fit(previsores_treinamento, classe_treinamento,
                  batch_size = 10, epochs = 100)

previsoes = classificador.predict(previsores_teste)
previsoes = (previsoes > 0.5)
from sklearn.metrics import confusion_matrix, accuracy_score
precisao = accuracy_score(classe_teste, previsoes)
matriz = confusion_matrix(classe_teste, previsoes)


resultado = classificador.evaluate(previsores_teste, classe_teste)


=================================================
visualização dos pesos
-------------------------------------------------
#setando a rede neural, sua primeira camada e pegando seu peso
pesos0 = classificador.layers[0].get_weights()
#print da variavel
print(pesos0)
#print do seu tamanho
print(len(pesos0))

#o mesmo para as segunda camada oculta e para camada de saida
#a segundda linha que exibe na matriz são os numeros de bias e seus pesos
    #por padrão ela vem setada
pesos1 = classificador.layers[1].get_weights()
pesos2 = classificador.layers[2].get_weights()