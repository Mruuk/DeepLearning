Ténica dropout serve para corrigir ou amênisar o overfitting.

ela serve prar zera alguns valores das camadas, geralmente é utilizado entre
20 a 30 porcento dos neurônios. Caso uso porcentagens mais altas, entrará no caso de underfitting,
pois estará matando os valores demais e a rede neural não conseguirá aprender.

DOCUMENTAÇÃO -: https://keras.io/api/layers/regularization_layers/dropout/#dropout-layer

    implementação
        #importação do Dropout
        from keras.layers import Dense, Dropout 
        
        #cria uma camada e add o dropout com a rate,
        #   neste caso irá zerar 20% dos neurônios da camada anterior a qual foi colocado            
        classificador.add(Dropout(0.2))